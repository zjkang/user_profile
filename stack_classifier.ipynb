{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configure & util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class param:\n",
    "    '''\n",
    "    there are total 100,000 samples in the train file\n",
    "    split train data into train' & test' and use train' for cross validation\n",
    "    '''\n",
    "    train_num = 75000 \n",
    "    test_num = 25000\n",
    "    w2v_dim = 300\n",
    "\n",
    "    seed = 2017\n",
    "\n",
    "# record data column names\n",
    "columns = ['Age', 'Gender', 'Education', 'Queries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class util:\n",
    "    @staticmethod\n",
    "    def log(stri):\n",
    "        now = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "        print(str(now) + ' ' + str(stri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf stacking features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "############################ 定义评估函数 ############################\n",
    "def micro_avg_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "############################ 加载数据 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8')\n",
    "\n",
    "############################ tfidf ############################\n",
    "tfv = TfidfVectorizer(min_df=3, max_df=0.95, sublinear_tf=True)\n",
    "x_sp = tfv.fit_transform(df_all['Queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 285214)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import param\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:22:00 stack:1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:22:33 va acc:0.798733\n",
      "2021-02-09 21:22:33 stack:2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:23:09 va acc:0.796600\n",
      "2021-02-09 21:23:09 stack:3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:23:44 va acc:0.795733\n",
      "2021-02-09 21:23:44 stack:4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:24:18 va acc:0.799400\n",
      "2021-02-09 21:24:18 stack:5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:24:52 va acc:0.803800\n",
      "2021-02-09 21:24:52 va avg acc:0.798853\n"
     ]
    }
   ],
   "source": [
    "############################ lr stack ############################\n",
    "tr_num = param.train_num\n",
    "num_class = len(pd.value_counts(df_all['Gender']))\n",
    "n = 5\n",
    "\n",
    "x = x_sp[:tr_num]\n",
    "y = df_all['Gender'][:tr_num]\n",
    "x_te = x_sp[tr_num:]\n",
    "# y_te = df_all['Gender'][tr_num:]\n",
    "\n",
    "stack = np.zeros((x.shape[0], num_class))\n",
    "stack_te = np.zeros((x_te.shape[0], num_class))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n, random_state=param.seed)\n",
    "\n",
    "score_va = 0\n",
    "# score_te = 0\n",
    "i = 0\n",
    "for tr, va in skf.split(x, y):\n",
    "    util.log('stack:%d/%d' % ((i + 1), n))\n",
    "    clf = LogisticRegression(C=2)\n",
    "    clf.fit(x[tr], y[tr])\n",
    "    y_pred_va = clf.predict_proba(x[va])\n",
    "    y_pred_te = clf.predict_proba(x_te)\n",
    "    util.log('va acc:%f' % micro_avg_f1(y[va], clf.predict(x[va])))\n",
    "#     util.log('te acc:%f' % micro_avg_f1(y_te, clf.predict(x_te)))\n",
    "    score_va += micro_avg_f1(y[va], clf.predict(x[va]))\n",
    "#     score_te += micro_avg_f1(y_te, clf.predict(x_te))\n",
    "    stack[va] += y_pred_va\n",
    "    stack_te += y_pred_te\n",
    "    i += 1\n",
    "score_va /= n\n",
    "# score_te /= n\n",
    "util.log('va avg acc:%f' % score_va)\n",
    "# util.log('te avg acc:%f' % score_te)\n",
    "stack_te /= n\n",
    "stack_all = np.vstack([stack, stack_te])\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_lr_{}'.format(i)] = stack_all[:, i]\n",
    "\n",
    "df_stack.to_csv('./output/feature/tfidf/lr_prob_21w.csv', index=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_lr_0</th>\n",
       "      <th>tfidf_lr_1</th>\n",
       "      <th>tfidf_lr_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031184</td>\n",
       "      <td>0.415349</td>\n",
       "      <td>0.553467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019671</td>\n",
       "      <td>0.893681</td>\n",
       "      <td>0.086648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008075</td>\n",
       "      <td>0.895271</td>\n",
       "      <td>0.096654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009420</td>\n",
       "      <td>0.034293</td>\n",
       "      <td>0.956287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.051781</td>\n",
       "      <td>0.936184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_lr_0  tfidf_lr_1  tfidf_lr_2\n",
       "0    0.031184    0.415349    0.553467\n",
       "1    0.019671    0.893681    0.086648\n",
       "2    0.008075    0.895271    0.096654\n",
       "3    0.009420    0.034293    0.956287\n",
       "4    0.012034    0.051781    0.936184"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:29:14 stack:1/5\n",
      "2021-02-09 21:29:15 va acc:0.797600\n",
      "2021-02-09 21:29:15 stack:2/5\n",
      "2021-02-09 21:29:15 va acc:0.798000\n",
      "2021-02-09 21:29:15 stack:3/5\n",
      "2021-02-09 21:29:16 va acc:0.793533\n",
      "2021-02-09 21:29:16 stack:4/5\n",
      "2021-02-09 21:29:17 va acc:0.801533\n",
      "2021-02-09 21:29:17 stack:5/5\n",
      "2021-02-09 21:29:18 va acc:0.802600\n",
      "2021-02-09 21:29:18 va avg acc:0.798653\n"
     ]
    }
   ],
   "source": [
    "############################ bnb stack ############################\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "tr_num = param.train_num\n",
    "num_class = len(pd.value_counts(df_all['Gender']))\n",
    "n = 5\n",
    "\n",
    "x = x_sp[:tr_num]\n",
    "y = df_all['Gender'][:tr_num]\n",
    "x_te = x_sp[tr_num:]\n",
    "# y_te = df_all['Gender'][tr_num:]\n",
    "\n",
    "stack = np.zeros((x.shape[0], num_class))\n",
    "stack_te = np.zeros((x_te.shape[0], num_class))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n, random_state=param.seed)\n",
    "\n",
    "score_va = 0\n",
    "# score_te = 0\n",
    "i = 0\n",
    "for tr, va in skf.split(x, y):\n",
    "    util.log('stack:%d/%d' % ((i + 1), n))\n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(x[tr], y[tr])\n",
    "    y_pred_va = clf.predict_proba(x[va])\n",
    "    y_pred_te = clf.predict_proba(x_te)\n",
    "    util.log('va acc:%f' % micro_avg_f1(y[va], clf.predict(x[va])))\n",
    "#     util.log('te acc:%f' % micro_avg_f1(y_te, clf.predict(x_te)))\n",
    "    score_va += micro_avg_f1(y[va], clf.predict(x[va]))\n",
    "#     score_te += micro_avg_f1(y_te, clf.predict(x_te))\n",
    "    stack[va] += y_pred_va\n",
    "    stack_te += y_pred_te\n",
    "    i += 1\n",
    "score_va /= n\n",
    "# score_te /= n\n",
    "util.log('va avg acc:%f' % score_va)\n",
    "# util.log('te avg acc:%f' % score_te)\n",
    "stack_te /= n\n",
    "stack_all = np.vstack([stack, stack_te])\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_bnb_{}'.format(i)] = stack_all[:, i]\n",
    "\n",
    "df_stack.to_csv('./output/feature/tfidf/bnb_prob_21w.csv', index=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhengjiankang/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 21:45:07 stack:1/5\n",
      "2021-02-09 21:45:07 va acc:0.777800\n",
      "2021-02-09 21:45:07 stack:2/5\n",
      "2021-02-09 21:45:08 va acc:0.775933\n",
      "2021-02-09 21:45:08 stack:3/5\n",
      "2021-02-09 21:45:08 va acc:0.779000\n",
      "2021-02-09 21:45:08 stack:4/5\n",
      "2021-02-09 21:45:09 va acc:0.780800\n",
      "2021-02-09 21:45:09 stack:5/5\n",
      "2021-02-09 21:45:09 va acc:0.781200\n",
      "2021-02-09 21:45:09 va avg acc:0.778947\n"
     ]
    }
   ],
   "source": [
    "############################ mnb stack ############################\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "tr_num = param.train_num\n",
    "num_class = len(pd.value_counts(df_all['Gender']))\n",
    "n = 5\n",
    "\n",
    "x = x_sp[:tr_num]\n",
    "y = df_all['Gender'][:tr_num]\n",
    "x_te = x_sp[tr_num:]\n",
    "# y_te = df_all['Gender'][tr_num:]\n",
    "\n",
    "stack = np.zeros((x.shape[0], num_class))\n",
    "stack_te = np.zeros((x_te.shape[0], num_class))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n, random_state=param.seed)\n",
    "\n",
    "score_va = 0\n",
    "# score_te = 0\n",
    "i = 0\n",
    "for tr, va in skf.split(x, y):\n",
    "    util.log('stack:%d/%d' % ((i + 1), n))\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(x[tr], y[tr])\n",
    "    y_pred_va = clf.predict_proba(x[va])\n",
    "    y_pred_te = clf.predict_proba(x_te)\n",
    "    util.log('va acc:%f' % micro_avg_f1(y[va], clf.predict(x[va])))\n",
    "#     util.log('te acc:%f' % micro_avg_f1(y_te, clf.predict(x_te)))\n",
    "    score_va += micro_avg_f1(y[va], clf.predict(x[va]))\n",
    "#     score_te += micro_avg_f1(y_te, clf.predict(x_te))\n",
    "    stack[va] += y_pred_va\n",
    "    stack_te += y_pred_te\n",
    "    i += 1\n",
    "score_va /= n\n",
    "# score_te /= n\n",
    "util.log('va avg acc:%f' % score_va)\n",
    "# util.log('te avg acc:%f' % score_te)\n",
    "stack_te /= n\n",
    "stack_all = np.vstack([stack, stack_te])\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_mnb_{}'.format(i)] = stack_all[:, i]\n",
    "\n",
    "df_stack.to_csv('./output/feature/tfidf/mnb_prob_21w.csv', index=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec stacking features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import codecs\n",
    "import subprocess\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "############################ 加载数据 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8').reset_index()\n",
    "\n",
    "\n",
    "############################ 定义函数、类及变量 ############################\n",
    "def run_cmd(cmd):\n",
    "    print(cmd)\n",
    "    process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "    for t, line in enumerate(iter(process.stdout.readline, b'')):\n",
    "        line = line.decode('utf8').rstrip()\n",
    "        print(line)\n",
    "    process.communicate()\n",
    "    return process.returncode\n",
    "\n",
    "\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags')\n",
    "\n",
    "\n",
    "class Doc_list(object):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def __iter__(self):\n",
    "        for i,line in enumerate(codecs.open(self.f,encoding='utf8')):\n",
    "            words = line.strip().split(' ')\n",
    "            tags = [int(words[0][2:])]\n",
    "            words = words[1:]\n",
    "            yield SentimentDocument(words,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 22:13:37 iter = 0\n",
      "2021-02-09 22:13:38 iter = 10000\n",
      "2021-02-09 22:13:39 iter = 20000\n",
      "2021-02-09 22:13:40 iter = 30000\n",
      "2021-02-09 22:13:41 iter = 40000\n",
      "2021-02-09 22:13:42 iter = 50000\n",
      "2021-02-09 22:13:43 iter = 60000\n",
      "2021-02-09 22:13:44 iter = 70000\n",
      "2021-02-09 22:13:45 iter = 80000\n",
      "2021-02-09 22:13:46 iter = 90000\n"
     ]
    }
   ],
   "source": [
    "############################ 准备数据 ############################\n",
    "doc_f = codecs.open('./output/corpus/doc_for_d2v_21w.txt', 'w', encoding='utf8')\n",
    "for i, contents in enumerate(df_all.iloc[:(param.train_num+param.test_num)]['Queries']):\n",
    "    words = []\n",
    "    for word in contents.split(' '):\n",
    "        words.append(word)\n",
    "    tags = [i]\n",
    "    if i % 10000 == 0:\n",
    "        util.log('iter = %d' % i)\n",
    "    doc_f.write(u'_*{} {}\\n'.format(i, ' '.join(words)))\n",
    "doc_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dbow stacking doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 22:20:01 pass: 0\n",
      "2021-02-09 22:24:12 dbow: [0.8097  0.80665 0.81315 0.81525 0.813  ] 0.8115499999999999\n",
      "2021-02-09 22:24:12 pass: 1\n",
      "2021-02-09 22:28:14 dbow: [0.8168 0.812  0.8173 0.8208 0.8167] 0.8167199999999999\n",
      "2021-02-09 22:28:14 pass: 2\n",
      "2021-02-09 22:32:40 dbow: [0.81725 0.81195 0.81755 0.82075 0.81955] 0.81741\n",
      "2021-02-09 22:32:40 pass: 3\n",
      "2021-02-09 22:37:04 dbow: [0.81545 0.8133  0.81645 0.8206  0.8196 ] 0.8170800000000001\n",
      "2021-02-09 22:37:04 pass: 4\n",
      "2021-02-09 22:41:37 dbow: [0.81765 0.8118  0.81805 0.8221  0.8197 ] 0.8178599999999999\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'param' has no attribute 'data_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e656f0d230cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_d2v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_lb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dbow: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0md2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'./output/model/dbow_d2v_21w.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Save done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'param' has no attribute 'data_path'"
     ]
    }
   ],
   "source": [
    "############################ dbow d2v ############################\n",
    "d2v = Doc2Vec(dm=0, size=300, negative=5, hs=0, min_count=3, window=30, sample=1e-5, workers=8, alpha=0.025, min_alpha=0.025)\n",
    "doc_list = Doc_list('./output/corpus/doc_for_d2v_21w.txt')\n",
    "d2v.build_vocab(doc_list)\n",
    "\n",
    "df_lb = df_all['Gender']\n",
    "\n",
    "# use fewer iterations\n",
    "for i in range(5):\n",
    "    util.log('pass: ' + str(i))\n",
    "    #     run_cmd('shuf alldata-id.txt > alldata-id-shuf.txt')\n",
    "    doc_list = Doc_list('./output/corpus/doc_for_d2v_21w.txt')\n",
    "    d2v.train(doc_list, total_examples=d2v.corpus_count, epochs=d2v.iter)\n",
    "    X_d2v = np.array([d2v.docvecs[i] for i in range(param.train_num+param.test_num)])\n",
    "    scores = cross_val_score(LogisticRegression(C=3), X_d2v, df_lb, cv=5)\n",
    "    util.log('dbow: ' + str(scores) + ' ' + str(np.mean(scores)))\n",
    "d2v.save('./output/model/dbow_d2v_21w.model')\n",
    "util.log('Save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 22:43:10 Save done!\n"
     ]
    }
   ],
   "source": [
    "d2v.save('./output/model/dbow_d2v_21w.model')\n",
    "util.log('Save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 00:12:43 stack:1/5\n",
      "Epoch 1/35\n",
      "469/469 - 2s - loss: 1.1389 - accuracy: 0.3710\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0051 - accuracy: 0.4667\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9089 - accuracy: 0.5303\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8433 - accuracy: 0.5710\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.7957 - accuracy: 0.6002\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7605 - accuracy: 0.6243\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7319 - accuracy: 0.6452\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7101 - accuracy: 0.6630\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.6906 - accuracy: 0.6789\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.6739 - accuracy: 0.6956\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.6596 - accuracy: 0.7084\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.6473 - accuracy: 0.7189\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6365 - accuracy: 0.7291\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6272 - accuracy: 0.7355\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6190 - accuracy: 0.7442\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6111 - accuracy: 0.7519\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6044 - accuracy: 0.7578\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.5992 - accuracy: 0.7617\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.5927 - accuracy: 0.7681\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.5882 - accuracy: 0.7696\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.5845 - accuracy: 0.7743\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.5807 - accuracy: 0.7768\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.5769 - accuracy: 0.7801\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.5731 - accuracy: 0.7826\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.5699 - accuracy: 0.7853\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.5667 - accuracy: 0.7862\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.5646 - accuracy: 0.7879\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.5628 - accuracy: 0.7886\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.5607 - accuracy: 0.7922\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.5591 - accuracy: 0.7927\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.5562 - accuracy: 0.7950\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.5554 - accuracy: 0.7959\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.5543 - accuracy: 0.7950\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.5513 - accuracy: 0.7989\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.5511 - accuracy: 0.7977\n",
      "2021-02-10 00:13:21 va acc:0.804867\n",
      "2021-02-10 00:13:21 te acc:0.803400\n",
      "2021-02-10 00:13:22 stack:2/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.2744 - accuracy: 0.2579\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0832 - accuracy: 0.4117\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9512 - accuracy: 0.5178\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8635 - accuracy: 0.5787\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8026 - accuracy: 0.6126\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7626 - accuracy: 0.6347\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7316 - accuracy: 0.6543\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7069 - accuracy: 0.6727\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.6888 - accuracy: 0.6833\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.6718 - accuracy: 0.7003\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.6582 - accuracy: 0.7114\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.6459 - accuracy: 0.7225\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6349 - accuracy: 0.7315\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6262 - accuracy: 0.7414\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6178 - accuracy: 0.7477\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6106 - accuracy: 0.7552\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6046 - accuracy: 0.7601\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.5986 - accuracy: 0.7659\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.5931 - accuracy: 0.7673\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.5881 - accuracy: 0.7722\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.5837 - accuracy: 0.7750\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.5798 - accuracy: 0.7785\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.5761 - accuracy: 0.7828\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.5739 - accuracy: 0.7829\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.5697 - accuracy: 0.7862\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.5671 - accuracy: 0.7883\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.5646 - accuracy: 0.7894\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.5623 - accuracy: 0.7899\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.5605 - accuracy: 0.7920\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.5579 - accuracy: 0.7942\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.5574 - accuracy: 0.7953\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.5548 - accuracy: 0.7954\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.5532 - accuracy: 0.7975\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.5506 - accuracy: 0.7993\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.5502 - accuracy: 0.7987\n",
      "2021-02-10 00:13:57 va acc:0.801533\n",
      "2021-02-10 00:13:58 te acc:0.805600\n",
      "2021-02-10 00:13:59 stack:3/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.0767 - accuracy: 0.4440\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 0.9400 - accuracy: 0.5597\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.8462 - accuracy: 0.6169\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.7837 - accuracy: 0.6434\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.7393 - accuracy: 0.6618\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7086 - accuracy: 0.6798\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.6863 - accuracy: 0.6906\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.6670 - accuracy: 0.7068\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.6516 - accuracy: 0.7163\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.6395 - accuracy: 0.7278\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.6276 - accuracy: 0.7361\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.6200 - accuracy: 0.7427\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6119 - accuracy: 0.7496\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6047 - accuracy: 0.7547\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.5991 - accuracy: 0.7597\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.5928 - accuracy: 0.7644\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.5883 - accuracy: 0.7678\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.5837 - accuracy: 0.7710\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.5795 - accuracy: 0.7755\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.5766 - accuracy: 0.7768\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.5726 - accuracy: 0.7815\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.5704 - accuracy: 0.7826\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.5664 - accuracy: 0.7847\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.5643 - accuracy: 0.7876\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.5621 - accuracy: 0.7893\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.5598 - accuracy: 0.7906\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.5582 - accuracy: 0.7923\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.5572 - accuracy: 0.7922\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.5546 - accuracy: 0.7939\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.5538 - accuracy: 0.7959\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.5520 - accuracy: 0.7965\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.5510 - accuracy: 0.7958\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.5492 - accuracy: 0.7978\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.5489 - accuracy: 0.7991\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.5475 - accuracy: 0.7989\n",
      "2021-02-10 00:14:36 va acc:0.800400\n",
      "2021-02-10 00:14:37 te acc:0.805320\n",
      "2021-02-10 00:14:38 stack:4/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.0365 - accuracy: 0.4554\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 0.9318 - accuracy: 0.5250\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.8589 - accuracy: 0.5677\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8068 - accuracy: 0.5978\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.7695 - accuracy: 0.6215\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7411 - accuracy: 0.6401\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7172 - accuracy: 0.6597\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.6969 - accuracy: 0.6748\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.6794 - accuracy: 0.6896\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.6658 - accuracy: 0.7020\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.6522 - accuracy: 0.7147\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.6420 - accuracy: 0.7237\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6318 - accuracy: 0.7314\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6238 - accuracy: 0.7390\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6162 - accuracy: 0.7456\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6084 - accuracy: 0.7536\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6015 - accuracy: 0.7592\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.5973 - accuracy: 0.7626\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.5924 - accuracy: 0.7647\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.5868 - accuracy: 0.7714\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.5833 - accuracy: 0.7726\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.5802 - accuracy: 0.7750\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.5760 - accuracy: 0.7796\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.5735 - accuracy: 0.7797\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.5708 - accuracy: 0.7825\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.5684 - accuracy: 0.7855\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.5654 - accuracy: 0.7869\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.5629 - accuracy: 0.7882\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.5618 - accuracy: 0.7886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.5599 - accuracy: 0.7904\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.5581 - accuracy: 0.7918\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.5562 - accuracy: 0.7941\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.5549 - accuracy: 0.7952\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.5536 - accuracy: 0.7953\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.5513 - accuracy: 0.7975\n",
      "2021-02-10 00:15:14 va acc:0.800933\n",
      "2021-02-10 00:15:14 te acc:0.805240\n",
      "2021-02-10 00:15:15 stack:5/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.2053 - accuracy: 0.3307\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0277 - accuracy: 0.4612\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9106 - accuracy: 0.5397\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8366 - accuracy: 0.5805\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.7874 - accuracy: 0.6096\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7516 - accuracy: 0.6315\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7236 - accuracy: 0.6513\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7028 - accuracy: 0.6673\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.6835 - accuracy: 0.6849\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.6685 - accuracy: 0.6988\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.6551 - accuracy: 0.7121\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.6439 - accuracy: 0.7218\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6337 - accuracy: 0.7320\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6241 - accuracy: 0.7411\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6163 - accuracy: 0.7459\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6084 - accuracy: 0.7548\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6028 - accuracy: 0.7588\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.5972 - accuracy: 0.7631\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.5913 - accuracy: 0.7688\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.5876 - accuracy: 0.7714\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.5831 - accuracy: 0.7742\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.5796 - accuracy: 0.7773\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.5763 - accuracy: 0.7810\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.5726 - accuracy: 0.7817\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.5702 - accuracy: 0.7843\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.5668 - accuracy: 0.7880\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.5655 - accuracy: 0.7879\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.5634 - accuracy: 0.7888\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.5607 - accuracy: 0.7921\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.5588 - accuracy: 0.7933\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.5569 - accuracy: 0.7950\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.5557 - accuracy: 0.7960\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.5548 - accuracy: 0.7954\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.5532 - accuracy: 0.7979\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.5518 - accuracy: 0.7978\n",
      "2021-02-10 00:15:52 va acc:0.807067\n",
      "2021-02-10 00:15:52 te acc:0.805800\n",
      "2021-02-10 00:15:53 va avg acc:0.802960\n",
      "2021-02-10 00:15:53 te avg acc:0.805072\n",
      "2021-02-10 00:15:54 Save dbowd2v stack done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "############################ 定义评估函数 ############################\n",
    "def micro_avg_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "############################ 加载数据 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8')\n",
    "\n",
    "model = Doc2Vec.load('./output/model/dbow_d2v_21w.model')\n",
    "x_sp = np.array([model.docvecs[i] for i in range(param.train_num+param.test_num)])\n",
    "\n",
    "\n",
    "############################ dbowd2v stack ############################\n",
    "np.random.seed(param.seed) # 固定种子，方便复现\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "tr_num = param.train_num\n",
    "num_class = len(pd.value_counts(df_all['Gender']))\n",
    "n = 5\n",
    "\n",
    "x = x_sp[:tr_num]\n",
    "y = df_all['Gender'][:tr_num]\n",
    "x_te = x_sp[tr_num:]\n",
    "y_te = df_all['Gender'][tr_num:]\n",
    "\n",
    "feat = 'dbowd2v'\n",
    "stack = np.zeros((x.shape[0], num_class))\n",
    "stack_te = np.zeros((x_te.shape[0], num_class))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n, random_state=param.seed)\n",
    "\n",
    "score_va = 0\n",
    "score_te = 0\n",
    "i = 0\n",
    "for tr, va in skf.split(x, y):\n",
    "    util.log('stack:%d/%d' % ((i + 1), n))\n",
    "    y_train = np_utils.to_categorical(y[tr], num_class)\n",
    "    y_test = np_utils.to_categorical(y_te, num_class)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_shape=(x[tr].shape[1],)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(num_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(x[tr], y_train, shuffle=True,\n",
    "                        batch_size=128, epochs=35,\n",
    "                        verbose=2)\n",
    "    y_pred_va = model.predict_proba(x[va])\n",
    "    y_pred_te = model.predict_proba(x_te)\n",
    "    util.log('va acc:%f' % micro_avg_f1(y[va], model.predict_classes(x[va])))\n",
    "    util.log('te acc:%f' % micro_avg_f1(y_te, model.predict_classes(x_te)))\n",
    "    score_va += micro_avg_f1(y[va], model.predict_classes(x[va]))\n",
    "    score_te += micro_avg_f1(y_te, model.predict_classes(x_te))\n",
    "    stack[va] += y_pred_va\n",
    "    stack_te += y_pred_te\n",
    "    i += 1\n",
    "score_va /= n\n",
    "score_te /= n\n",
    "util.log('va avg acc:%f' % score_va)\n",
    "util.log('te avg acc:%f' % score_te)\n",
    "stack_te /= n\n",
    "stack_all = np.vstack([stack, stack_te])\n",
    "for l in range(stack_all.shape[1]):\n",
    "    df_stack['{}_{}'.format(feat, l)] = stack_all[:, l]\n",
    "\n",
    "df_stack.to_csv('./output/feature/dbowd2v/nn_prob_21w.csv', encoding='utf8', index=None)\n",
    "util.log('Save dbowd2v stack done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dm stacking doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 22:45:32 pass: 0\n",
      "2021-02-09 22:52:43 dm: [0.7127  0.72995 0.74365 0.73345 0.72595] 0.72914\n",
      "2021-02-09 22:52:43 pass: 1\n",
      "2021-02-09 23:10:41 dm: [0.73065 0.7332  0.74545 0.74175 0.73335] 0.73688\n",
      "2021-02-09 23:10:41 pass: 2\n",
      "2021-02-09 23:17:13 dm: [0.74635 0.74145 0.7538  0.7507  0.7435 ] 0.74716\n",
      "2021-02-09 23:17:13 pass: 3\n",
      "2021-02-09 23:23:54 dm: [0.7534  0.74835 0.76115 0.7577  0.75225] 0.75457\n",
      "2021-02-09 23:23:54 pass: 4\n",
      "2021-02-09 23:31:09 dm: [0.75815 0.7551  0.767   0.76385 0.7595 ] 0.7607200000000001\n",
      "2021-02-09 23:31:18 Save done!\n"
     ]
    }
   ],
   "source": [
    "############################ dm d2v ############################\n",
    "d2v = Doc2Vec(dm=1, size=300, negative=5, hs=0, min_count=3, window=30, sample=1e-5, workers=8, alpha=0.025, min_alpha=0.025)\n",
    "doc_list = Doc_list('./output/corpus/doc_for_d2v_21w.txt')\n",
    "d2v.build_vocab(doc_list)\n",
    "\n",
    "df_lb = df_all['Gender']\n",
    "\n",
    "# change from 10 to 5\n",
    "for i in range(5):\n",
    "    util.log('pass: ' + str(i))\n",
    "    #     run_cmd('shuf alldata-id.txt > alldata-id-shuf.txt')\n",
    "    doc_list = Doc_list('./output/corpus/doc_for_d2v_21w.txt')\n",
    "    d2v.train(doc_list, total_examples=d2v.corpus_count, epochs=d2v.iter)\n",
    "    X_d2v = np.array([d2v.docvecs[i] for i in range(param.train_num+param.test_num)])\n",
    "    scores = cross_val_score(LogisticRegression(C=3), X_d2v, df_lb, cv=5)\n",
    "    util.log('dm: ' + str(scores) + ' ' + str(np.mean(scores)))\n",
    "d2v.save('./output/model/dm_d2v_21w.model')\n",
    "util.log('Save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-10 00:19:55 stack:1/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.1844 - accuracy: 0.3887\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0095 - accuracy: 0.4839\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9157 - accuracy: 0.5329\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8619 - accuracy: 0.5601\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8279 - accuracy: 0.5770\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.8008 - accuracy: 0.5950\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7795 - accuracy: 0.6090\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7631 - accuracy: 0.6185\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.7479 - accuracy: 0.6334\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.7364 - accuracy: 0.6414\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.7230 - accuracy: 0.6520\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.7132 - accuracy: 0.6591\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.7038 - accuracy: 0.6695\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6968 - accuracy: 0.6745\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6897 - accuracy: 0.6810\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6828 - accuracy: 0.6871\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6775 - accuracy: 0.6925\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.6716 - accuracy: 0.6975\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.6679 - accuracy: 0.7001\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.6643 - accuracy: 0.7044\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.6597 - accuracy: 0.7090\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.6558 - accuracy: 0.7120\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.6538 - accuracy: 0.7142\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.6508 - accuracy: 0.7177\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.6470 - accuracy: 0.7198\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.6439 - accuracy: 0.7230\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.6434 - accuracy: 0.7229\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.6412 - accuracy: 0.7250\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.6366 - accuracy: 0.7270\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.6367 - accuracy: 0.7281\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.6351 - accuracy: 0.7286\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.6331 - accuracy: 0.7308\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.6316 - accuracy: 0.7309\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.6308 - accuracy: 0.7338\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.6297 - accuracy: 0.7340\n",
      "2021-02-10 00:20:31 va acc:0.734267\n",
      "2021-02-10 00:20:31 te acc:0.740320\n",
      "2021-02-10 00:20:32 stack:2/5\n",
      "Epoch 1/35\n",
      "469/469 - 2s - loss: 1.2424 - accuracy: 0.3540\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0593 - accuracy: 0.4562\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9600 - accuracy: 0.5021\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8997 - accuracy: 0.5303\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8574 - accuracy: 0.5545\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.8256 - accuracy: 0.5725\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7995 - accuracy: 0.5902\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7774 - accuracy: 0.6060\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.7596 - accuracy: 0.6213\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.7421 - accuracy: 0.6354\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.7314 - accuracy: 0.6464\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.7196 - accuracy: 0.6557\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.7087 - accuracy: 0.6643\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.7001 - accuracy: 0.6727\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6927 - accuracy: 0.6782\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6855 - accuracy: 0.6863\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6789 - accuracy: 0.6899\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.6732 - accuracy: 0.6960\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.6691 - accuracy: 0.7013\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.6647 - accuracy: 0.7045\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.6600 - accuracy: 0.7076\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.6560 - accuracy: 0.7119\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.6529 - accuracy: 0.7136\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.6485 - accuracy: 0.7183\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.6481 - accuracy: 0.7172\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.6449 - accuracy: 0.7207\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.6408 - accuracy: 0.7234\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.6401 - accuracy: 0.7241\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.6380 - accuracy: 0.7279\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.6375 - accuracy: 0.7261\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.6355 - accuracy: 0.7297\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.6330 - accuracy: 0.7333\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.6324 - accuracy: 0.7309\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.6308 - accuracy: 0.7327\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.6284 - accuracy: 0.7339\n",
      "2021-02-10 00:21:07 va acc:0.736600\n",
      "2021-02-10 00:21:08 te acc:0.742240\n",
      "2021-02-10 00:21:09 stack:3/5\n",
      "Epoch 1/35\n",
      "469/469 - 1s - loss: 1.1592 - accuracy: 0.4291\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 0.9991 - accuracy: 0.5045\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9081 - accuracy: 0.5395\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8519 - accuracy: 0.5623\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8145 - accuracy: 0.5845\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7874 - accuracy: 0.6002\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7673 - accuracy: 0.6140\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7502 - accuracy: 0.6285\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.7352 - accuracy: 0.6397\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.7240 - accuracy: 0.6491\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.7114 - accuracy: 0.6583\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.7031 - accuracy: 0.6681\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.6948 - accuracy: 0.6764\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6881 - accuracy: 0.6812\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6806 - accuracy: 0.6887\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6756 - accuracy: 0.6930\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6702 - accuracy: 0.6976\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.6668 - accuracy: 0.7019\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.6610 - accuracy: 0.7055\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.6584 - accuracy: 0.7089\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.6546 - accuracy: 0.7117\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.6520 - accuracy: 0.7135\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.6494 - accuracy: 0.7162\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.6456 - accuracy: 0.7186\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.6442 - accuracy: 0.7205\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.6399 - accuracy: 0.7233\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.6392 - accuracy: 0.7240\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.6381 - accuracy: 0.7258\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.6361 - accuracy: 0.7276\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.6333 - accuracy: 0.7302\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.6320 - accuracy: 0.7308\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.6312 - accuracy: 0.7308\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.6284 - accuracy: 0.7341\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.6287 - accuracy: 0.7338\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.6272 - accuracy: 0.7332\n",
      "2021-02-10 00:21:49 va acc:0.743467\n",
      "2021-02-10 00:21:50 te acc:0.739480\n",
      "2021-02-10 00:21:52 stack:4/5\n",
      "Epoch 1/35\n",
      "469/469 - 2s - loss: 1.2821 - accuracy: 0.3343\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 1.0600 - accuracy: 0.4707\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.9429 - accuracy: 0.5320\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8746 - accuracy: 0.5613\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8300 - accuracy: 0.5824\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.8017 - accuracy: 0.5968\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7773 - accuracy: 0.6125\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7597 - accuracy: 0.6239\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.7451 - accuracy: 0.6361\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.7321 - accuracy: 0.6460\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.7215 - accuracy: 0.6553\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.7118 - accuracy: 0.6641\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.7037 - accuracy: 0.6704\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6968 - accuracy: 0.6748\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6898 - accuracy: 0.6823\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6833 - accuracy: 0.6879\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6781 - accuracy: 0.6920\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.6742 - accuracy: 0.6971\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.6696 - accuracy: 0.6995\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.6640 - accuracy: 0.7062\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.6611 - accuracy: 0.7087\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.6587 - accuracy: 0.7099\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.6539 - accuracy: 0.7128\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.6522 - accuracy: 0.7161\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.6492 - accuracy: 0.7185\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.6467 - accuracy: 0.7198\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.6447 - accuracy: 0.7209\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.6432 - accuracy: 0.7224\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.6411 - accuracy: 0.7254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.6388 - accuracy: 0.7280\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.6378 - accuracy: 0.7272\n",
      "Epoch 32/35\n",
      "469/469 - 2s - loss: 0.6363 - accuracy: 0.7298\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.6349 - accuracy: 0.7315\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.6339 - accuracy: 0.7306\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.6312 - accuracy: 0.7328\n",
      "2021-02-10 00:22:38 va acc:0.742467\n",
      "2021-02-10 00:22:39 te acc:0.738520\n",
      "2021-02-10 00:22:40 stack:5/5\n",
      "Epoch 1/35\n",
      "469/469 - 2s - loss: 1.1194 - accuracy: 0.4228\n",
      "Epoch 2/35\n",
      "469/469 - 1s - loss: 0.9756 - accuracy: 0.5009\n",
      "Epoch 3/35\n",
      "469/469 - 1s - loss: 0.8971 - accuracy: 0.5415\n",
      "Epoch 4/35\n",
      "469/469 - 1s - loss: 0.8500 - accuracy: 0.5653\n",
      "Epoch 5/35\n",
      "469/469 - 1s - loss: 0.8194 - accuracy: 0.5832\n",
      "Epoch 6/35\n",
      "469/469 - 1s - loss: 0.7939 - accuracy: 0.5993\n",
      "Epoch 7/35\n",
      "469/469 - 1s - loss: 0.7742 - accuracy: 0.6142\n",
      "Epoch 8/35\n",
      "469/469 - 1s - loss: 0.7580 - accuracy: 0.6257\n",
      "Epoch 9/35\n",
      "469/469 - 1s - loss: 0.7457 - accuracy: 0.6354\n",
      "Epoch 10/35\n",
      "469/469 - 1s - loss: 0.7327 - accuracy: 0.6466\n",
      "Epoch 11/35\n",
      "469/469 - 1s - loss: 0.7216 - accuracy: 0.6564\n",
      "Epoch 12/35\n",
      "469/469 - 1s - loss: 0.7140 - accuracy: 0.6628\n",
      "Epoch 13/35\n",
      "469/469 - 1s - loss: 0.7048 - accuracy: 0.6715\n",
      "Epoch 14/35\n",
      "469/469 - 1s - loss: 0.6971 - accuracy: 0.6768\n",
      "Epoch 15/35\n",
      "469/469 - 1s - loss: 0.6917 - accuracy: 0.6834\n",
      "Epoch 16/35\n",
      "469/469 - 1s - loss: 0.6863 - accuracy: 0.6874\n",
      "Epoch 17/35\n",
      "469/469 - 1s - loss: 0.6800 - accuracy: 0.6936\n",
      "Epoch 18/35\n",
      "469/469 - 1s - loss: 0.6750 - accuracy: 0.6958\n",
      "Epoch 19/35\n",
      "469/469 - 1s - loss: 0.6705 - accuracy: 0.7023\n",
      "Epoch 20/35\n",
      "469/469 - 1s - loss: 0.6668 - accuracy: 0.7033\n",
      "Epoch 21/35\n",
      "469/469 - 1s - loss: 0.6634 - accuracy: 0.7080\n",
      "Epoch 22/35\n",
      "469/469 - 1s - loss: 0.6606 - accuracy: 0.7089\n",
      "Epoch 23/35\n",
      "469/469 - 1s - loss: 0.6568 - accuracy: 0.7129\n",
      "Epoch 24/35\n",
      "469/469 - 1s - loss: 0.6547 - accuracy: 0.7154\n",
      "Epoch 25/35\n",
      "469/469 - 1s - loss: 0.6523 - accuracy: 0.7173\n",
      "Epoch 26/35\n",
      "469/469 - 1s - loss: 0.6504 - accuracy: 0.7183\n",
      "Epoch 27/35\n",
      "469/469 - 1s - loss: 0.6473 - accuracy: 0.7222\n",
      "Epoch 28/35\n",
      "469/469 - 1s - loss: 0.6455 - accuracy: 0.7228\n",
      "Epoch 29/35\n",
      "469/469 - 1s - loss: 0.6430 - accuracy: 0.7245\n",
      "Epoch 30/35\n",
      "469/469 - 1s - loss: 0.6414 - accuracy: 0.7266\n",
      "Epoch 31/35\n",
      "469/469 - 1s - loss: 0.6402 - accuracy: 0.7280\n",
      "Epoch 32/35\n",
      "469/469 - 1s - loss: 0.6395 - accuracy: 0.7271\n",
      "Epoch 33/35\n",
      "469/469 - 1s - loss: 0.6372 - accuracy: 0.7293\n",
      "Epoch 34/35\n",
      "469/469 - 1s - loss: 0.6363 - accuracy: 0.7308\n",
      "Epoch 35/35\n",
      "469/469 - 1s - loss: 0.6344 - accuracy: 0.7315\n",
      "2021-02-10 00:23:26 va acc:0.745533\n",
      "2021-02-10 00:23:27 te acc:0.741680\n",
      "2021-02-10 00:23:28 va avg acc:0.740467\n",
      "2021-02-10 00:23:28 te avg acc:0.740448\n",
      "2021-02-10 00:23:29 Save dmd2v stack done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Doc2Vec\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "############################ 定义评估函数 ############################\n",
    "def micro_avg_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "############################ 加载数据 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8')\n",
    "\n",
    "model = Doc2Vec.load('./output/model/dm_d2v_21w.model')\n",
    "x_sp = np.array([model.docvecs[i] for i in range(param.train_num+param.test_num)])\n",
    "\n",
    "############################ dmd2v stack ############################\n",
    "np.random.seed(param.seed) # 固定种子，方便复现\n",
    "df_stack = pd.DataFrame(index=range(len(df_all)))\n",
    "tr_num = param.train_num\n",
    "num_class = len(pd.value_counts(df_all['Gender']))\n",
    "n = 5\n",
    "\n",
    "x = x_sp[:tr_num]\n",
    "y = df_all['Gender'][:tr_num]\n",
    "x_te = x_sp[tr_num:]\n",
    "y_te = df_all['Gender'][tr_num:]\n",
    "\n",
    "feat = 'dmd2v'\n",
    "stack = np.zeros((x.shape[0], num_class))\n",
    "stack_te = np.zeros((x_te.shape[0], num_class))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n, random_state=param.seed)\n",
    "\n",
    "score_va = 0\n",
    "score_te = 0\n",
    "i = 0\n",
    "for tr, va in skf.split(x, y):\n",
    "    util.log('stack:%d/%d' % ((i + 1), n))\n",
    "    y_train = np_utils.to_categorical(y[tr], num_class)\n",
    "    y_test = np_utils.to_categorical(y_te, num_class)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(300, input_shape=(x[tr].shape[1],)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dense(num_class))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adadelta',\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(x[tr], y_train, shuffle=True,\n",
    "                        batch_size=128, epochs=35,\n",
    "                        verbose=2)\n",
    "    y_pred_va = model.predict_proba(x[va])\n",
    "    y_pred_te = model.predict_proba(x_te)\n",
    "    util.log('va acc:%f' % micro_avg_f1(y[va], model.predict_classes(x[va])))\n",
    "    util.log('te acc:%f' % micro_avg_f1(y_te, model.predict_classes(x_te)))\n",
    "    score_va += micro_avg_f1(y[va], model.predict_classes(x[va]))\n",
    "    score_te += micro_avg_f1(y_te, model.predict_classes(x_te))\n",
    "    stack[va] += y_pred_va\n",
    "    stack_te += y_pred_te\n",
    "    i += 1\n",
    "score_va /= n\n",
    "score_te /= n\n",
    "util.log('va avg acc:%f' % score_va)\n",
    "util.log('te avg acc:%f' % score_te)\n",
    "stack_te /= n\n",
    "stack_all = np.vstack([stack, stack_te])\n",
    "for l in range(stack_all.shape[1]):\n",
    "    df_stack['{}_{}'.format(feat, l)] = stack_all[:, l]\n",
    "\n",
    "df_stack.to_csv('./output/feature/dmd2v/nn_prob_21w.csv', encoding='utf8', index=None)\n",
    "util.log('Save dmd2v stack done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 23:36:30 documents number 100000\n",
      "2021-02-09 23:37:14 Train Model...\n",
      "2021-02-09 23:51:17 Save done!\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "############################ 加载数据 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8')\n",
    "\n",
    "\n",
    "############################ w2v ############################\n",
    "documents = df_all['Queries'].values\n",
    "util.log('documents number %d' % len(documents))\n",
    "\n",
    "texts = [[word for word in document.split(' ')] for document in documents]\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] >= 5] for text in texts]\n",
    "\n",
    "util.log('Train Model...')\n",
    "w2v = Word2Vec(texts, size=param.w2v_dim, window=5, iter=15, workers=12, seed=param.seed)\n",
    "w2v.save('./output/model/w2v_21w.model')\n",
    "util.log('Save done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-09 23:53:25 Start get w2v feat..\n",
      "2021-02-09 23:53:29 1000\n",
      "2021-02-09 23:53:32 2000\n",
      "2021-02-09 23:53:35 3000\n",
      "2021-02-09 23:53:38 4000\n",
      "2021-02-09 23:53:41 5000\n",
      "2021-02-09 23:53:43 6000\n",
      "2021-02-09 23:53:47 7000\n",
      "2021-02-09 23:53:50 8000\n",
      "2021-02-09 23:53:53 9000\n",
      "2021-02-09 23:53:56 10000\n",
      "2021-02-09 23:53:59 11000\n",
      "2021-02-09 23:54:02 12000\n",
      "2021-02-09 23:54:05 13000\n",
      "2021-02-09 23:54:08 14000\n",
      "2021-02-09 23:54:11 15000\n",
      "2021-02-09 23:54:15 16000\n",
      "2021-02-09 23:54:18 17000\n",
      "2021-02-09 23:54:21 18000\n",
      "2021-02-09 23:54:24 19000\n",
      "2021-02-09 23:54:26 20000\n",
      "2021-02-09 23:54:29 21000\n",
      "2021-02-09 23:54:32 22000\n",
      "2021-02-09 23:54:36 23000\n",
      "2021-02-09 23:54:40 24000\n",
      "2021-02-09 23:54:44 25000\n",
      "2021-02-09 23:54:48 26000\n",
      "2021-02-09 23:54:51 27000\n",
      "2021-02-09 23:54:54 28000\n",
      "2021-02-09 23:54:57 29000\n",
      "2021-02-09 23:55:00 30000\n",
      "2021-02-09 23:55:02 31000\n",
      "2021-02-09 23:55:05 32000\n",
      "2021-02-09 23:55:08 33000\n",
      "2021-02-09 23:55:10 34000\n",
      "2021-02-09 23:55:14 35000\n",
      "2021-02-09 23:55:17 36000\n",
      "2021-02-09 23:55:19 37000\n",
      "2021-02-09 23:55:22 38000\n",
      "2021-02-09 23:55:25 39000\n",
      "2021-02-09 23:55:28 40000\n",
      "2021-02-09 23:55:31 41000\n",
      "2021-02-09 23:55:33 42000\n",
      "2021-02-09 23:55:36 43000\n",
      "2021-02-09 23:55:39 44000\n",
      "2021-02-09 23:55:42 45000\n",
      "2021-02-09 23:55:45 46000\n",
      "2021-02-09 23:55:48 47000\n",
      "2021-02-09 23:55:51 48000\n",
      "2021-02-09 23:55:53 49000\n",
      "2021-02-09 23:55:56 50000\n",
      "2021-02-09 23:55:58 51000\n",
      "2021-02-09 23:56:01 52000\n",
      "2021-02-09 23:56:04 53000\n",
      "2021-02-09 23:56:07 54000\n",
      "2021-02-09 23:56:11 55000\n",
      "2021-02-09 23:56:16 56000\n",
      "2021-02-09 23:56:21 57000\n",
      "2021-02-09 23:56:24 58000\n",
      "2021-02-09 23:56:28 59000\n",
      "2021-02-09 23:56:31 60000\n",
      "2021-02-09 23:56:34 61000\n",
      "2021-02-09 23:56:37 62000\n",
      "2021-02-09 23:56:40 63000\n",
      "2021-02-09 23:56:44 64000\n",
      "2021-02-09 23:56:49 65000\n",
      "2021-02-09 23:56:52 66000\n",
      "2021-02-09 23:56:55 67000\n",
      "2021-02-09 23:56:58 68000\n",
      "2021-02-09 23:57:01 69000\n",
      "2021-02-09 23:57:04 70000\n",
      "2021-02-09 23:57:07 71000\n",
      "2021-02-09 23:57:09 72000\n",
      "2021-02-09 23:57:12 73000\n",
      "2021-02-09 23:57:15 74000\n",
      "2021-02-09 23:57:19 75000\n",
      "2021-02-09 23:57:21 76000\n",
      "2021-02-09 23:57:24 77000\n",
      "2021-02-09 23:57:27 78000\n",
      "2021-02-09 23:57:29 79000\n",
      "2021-02-09 23:57:32 80000\n",
      "2021-02-09 23:57:35 81000\n",
      "2021-02-09 23:57:37 82000\n",
      "2021-02-09 23:57:41 83000\n",
      "2021-02-09 23:57:43 84000\n",
      "2021-02-09 23:57:46 85000\n",
      "2021-02-09 23:57:49 86000\n",
      "2021-02-09 23:57:53 87000\n",
      "2021-02-09 23:57:56 88000\n",
      "2021-02-09 23:57:59 89000\n",
      "2021-02-09 23:58:03 90000\n",
      "2021-02-09 23:58:06 91000\n",
      "2021-02-09 23:58:09 92000\n",
      "2021-02-09 23:58:12 93000\n",
      "2021-02-09 23:58:15 94000\n",
      "2021-02-09 23:58:18 95000\n",
      "2021-02-09 23:58:21 96000\n",
      "2021-02-09 23:58:24 97000\n",
      "2021-02-09 23:58:28 98000\n",
      "2021-02-09 23:58:31 99000\n",
      "2021-02-09 23:58:34 100000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './output/feature/w2v/w2v_21w.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2005ce8638d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdf_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mdf_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'w2v_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdf_w2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./output/feature/w2v/w2v_21w.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mdf_w2v_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2v_feat_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mdf_w2v_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'w2v_avg_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_w2v_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3165\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3166\u001b[0m         )\n\u001b[0;32m-> 3167\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             )\n\u001b[1;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0;31m# No explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './output/feature/w2v/w2v_21w.csv'"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "############################ 加载数据 & 模型 ############################\n",
    "df_all = pd.read_csv('./data/processed_train.csv', encoding='utf8')\n",
    "documents = df_all['Queries'].values\n",
    "texts = [[word for word in document.split(' ')] for document in documents]\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] >= 5] for text in texts]\n",
    "\n",
    "model = Word2Vec.load('./output/model/w2v_21w.model')\n",
    "\n",
    "\n",
    "############################ w2v ############################\n",
    "util.log('Start get w2v feat..')\n",
    "w2v_feat = np.zeros((len(texts), param.w2v_dim))\n",
    "w2v_feat_avg = np.zeros((len(texts), param.w2v_dim))\n",
    "i = 0\n",
    "for line in texts:\n",
    "    num = 0\n",
    "    for word in line:\n",
    "        num += 1\n",
    "        vec = model[word]\n",
    "        w2v_feat[i, :] += vec\n",
    "    w2v_feat_avg[i, :] = w2v_feat[i, :] / num\n",
    "    i += 1\n",
    "    if i % 10000 == 0:\n",
    "        util.log(i)\n",
    "\n",
    "df_w2v = pd.DataFrame(w2v_feat)\n",
    "df_w2v.columns = ['w2v_' + str(i) for i in df_w2v.columns]\n",
    "df_w2v.to_csv('./output/feature/w2v/w2v_21w.csv', encoding='utf8', index=None)\n",
    "df_w2v_avg = pd.DataFrame(w2v_feat_avg)\n",
    "df_w2v_avg.columns = ['w2v_avg_' + str(i) for i in df_w2v_avg.columns]\n",
    "df_w2v_avg.to_csv('./output/feature/w2v/w2v_avg_21w.csv', encoding='utf8', index=None)\n",
    "\n",
    "util.log('Save w2v and w2v_avg feat done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 ID  Gender\n",
      "0  22DD920316420BE2DF8D6EE651BA174B       1\n",
      "1  43CC3AF5A8D6430A3B572337A889AFE4       1\n",
      "2  E97654BFF5570E2CCD433EA6128EAC19       1\n",
      "3  6931EFC26D229CCFCEA125D3F3C21E57       2\n",
      "4  E780470C3BB0D340334BD08CDCC3C71A       2\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "############################ 定义评估函数 ############################\n",
    "def micro_avg_f1(preds, dtrain):\n",
    "    print(preds)\n",
    "    y_true = dtrain.get_label()\n",
    "    return 'micro_avg_f1', f1_score(y_true, preds, average='micro')\n",
    "\n",
    "# def micro_avg_f1(y_true, y_pred):\n",
    "#     return f1_score(y_true, y_pred, average='micro')\n",
    "# def micro_avg_f1(preds, dtrain):\n",
    "#     y_true = dtrain.get_label()\n",
    "#     return f1_score(y_true, preds, average='micro')\n",
    "\n",
    "\n",
    "############################ 加载特征 & 标签 ############################\n",
    "df_tfidf_lr = pd.read_csv('./output/feature/tfidf/lr_prob_21w.csv')\n",
    "df_tfidf_bnb = pd.read_csv('./output/feature/tfidf/bnb_prob_21w.csv')\n",
    "df_tfidf_mnb = pd.read_csv('./output/feature/tfidf/mnb_prob_21w.csv')\n",
    "df_dbow_nn = pd.read_csv('./output/feature/dbowd2v/nn_prob_21w.csv')\n",
    "df_dm_nn = pd.read_csv('./output/feature/dmd2v/nn_prob_21w.csv')\n",
    "df_w2v = pd.read_csv('./output/feature/w2v/w2v_21w.csv')\n",
    "\n",
    "df_lb = pd.read_csv('./data/processed_train.csv', usecols=['ID', 'Gender'])\n",
    "print(df_lb.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tfidf_lr_0', 'tfidf_lr_1', 'tfidf_lr_2', 'tfidf_bnb_0', 'tfidf_bnb_1',\n",
      "       'tfidf_bnb_2', 'tfidf_mnb_0', 'tfidf_mnb_1', 'tfidf_mnb_2', 'dbowd2v_0',\n",
      "       ...\n",
      "       'w2v_290', 'w2v_291', 'w2v_292', 'w2v_293', 'w2v_294', 'w2v_295',\n",
      "       'w2v_296', 'w2v_297', 'w2v_298', 'w2v_299'],\n",
      "      dtype='object', length=312)\n",
      "(75000, 312)\n",
      "(75000,)\n",
      "[1 2 0]\n",
      "[1 2 0]\n"
     ]
    }
   ],
   "source": [
    "############################ xgboost ############################\n",
    "tr_num = param.train_num\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['ID'] = df_lb.iloc[tr_num:]['ID']\n",
    "seed = param.seed\n",
    "\n",
    "# n_trees = 1086  ##### ! #####\n",
    "n_trees = 10\n",
    "# esr = 100\n",
    "evals = 10\n",
    "\n",
    "df = pd.concat([df_tfidf_lr, df_tfidf_bnb, df_tfidf_mnb, df_dbow_nn, df_w2v], axis=1)\n",
    "print(df.columns)\n",
    "num_class = len(pd.value_counts(df_lb['Gender']))\n",
    "x = df.iloc[:tr_num]\n",
    "y = df_lb['Gender'][:tr_num].astype(int)\n",
    "x_te = df.iloc[tr_num:]\n",
    "y_te = df_lb['Gender'][tr_num:].astype(int)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y.unique())\n",
    "print(y_te.unique())\n",
    "\n",
    "max_depth = 7\n",
    "min_child_weight = 1\n",
    "subsample = 0.8\n",
    "colsample_bytree = 0.8\n",
    "gamma = 1\n",
    "lam = 0\n",
    "\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "#      'objective': 'multi:softprob',\n",
    "    'booster': 'gbtree',\n",
    "    'stratified': True,\n",
    "    'num_class': num_class,\n",
    "    'max_depth': max_depth,\n",
    "    'min_child_weight': min_child_weight,\n",
    "    'subsample': subsample,\n",
    "    'colsample_bytree': colsample_bytree,\n",
    "#     'gamma': gamma,\n",
    "#     'lambda': lam,\n",
    "    \n",
    "    'eta': 0.02,\n",
    "    'silent': 1,\n",
    "    'seed': seed,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        2\n",
       "4        2\n",
       "        ..\n",
       "74995    1\n",
       "74996    2\n",
       "74997    2\n",
       "74998    2\n",
       "74999    2\n",
       "Name: Gender, Length: 75000, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-11 08:58:01 start to train xgb...\n",
      "[08:58:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent, stratified } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[08:58:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\ttrain-mlogloss:1.08118\n",
      "[9]\ttrain-mlogloss:0.94817\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 3, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2888\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2889\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3565\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gender'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c504394cfacc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m bst = xgb.train(params, dtrain, n_trees, evals=watchlist, maximize=True,\n\u001b[1;32m      8\u001b[0m                 verbose_eval=evals)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gender'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/output/result/1209-xgb-tfidf_lr_bnb_mnb+amt+dbowd2v_nn+w2v-r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'records'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3035\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3114\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3567\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3568\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3569\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1157\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_safe_reshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype)\u001b[0m\n\u001b[1;32m   2715\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatetimeArray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_simple_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2717\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, values, placement, ndim)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_ndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0;34mf\"Wrong number of items passed {len(self.values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;34mf\"placement implies {len(self.mgr_locs)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 3, placement implies 1"
     ]
    }
   ],
   "source": [
    "util.log('start to train xgb...')\n",
    "dtrain = xgb.DMatrix(x, label=y)\n",
    "dtest = xgb.DMatrix(x_te)\n",
    "watchlist = [(dtrain, 'train')]\n",
    "# bst = xgb.train(params, dtrain, n_trees, evals=watchlist, feval=micro_avg_f1, maximize=True,\n",
    "#                 verbose_eval=evals)\n",
    "bst = xgb.train(params, dtrain, n_trees, evals=watchlist, maximize=True,\n",
    "                verbose_eval=evals)\n",
    "# df_sub['Gender'] = bst.predict(dtest).astype(int)\n",
    "# df_sub['ID'] = df_sub['ID'].astype(str)\n",
    "# df_sub.to_json(param.data_path + '/output/result/1209-xgb-tfidf_lr_bnb_mnb+amt+dbowd2v_nn+w2v-r' + str(n_trees) + '.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_avg_f1(y_te, df_sub['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = bst.predict(xg_test)\n",
    "# error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "# print('Test error using softmax = {}'.format(error_rate))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
